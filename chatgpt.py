import os
import re
import time
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
OPENAI_KEY = os.getenv("OPENAI_KEY")
MODEL = os.getenv("GPT_MODEL", "gpt-5")

client = OpenAI(api_key=OPENAI_KEY)

def clean_text(text):
    """PDF, TXT ë“±ì—ì„œ ì œì–´ë¬¸ì ì œê±°"""
    return re.sub(r"[\x00-\x1f\x7f-\x9f]+", " ", text).strip()

def chunk_text(text, size=6000):
    """ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì¼ì • ê¸¸ì´ë¡œ ë‚˜ëˆ”"""
    text = clean_text(text)
    return [text[i:i+size] for i in range(0, len(text), size)]

def send_to_chatGpt(messages, model=MODEL):
    """
    GPTì—ê²Œ ë©”ì‹œì§€ ì „ì†¡ (ê¸´ TXT íŒŒì¼ë„ ìë™ ë¶„í•  ì²˜ë¦¬)
    """
    try:
        last = messages[-1]
        blocks = []

        # ê¸°ë³¸ ì…ë ¥ í…ìŠ¤íŠ¸
        text = last.get("content", "").strip()
        if text:
            blocks.append({"type": "input_text", "text": text})

        # ì´ë¯¸ì§€
        if "image_base64" in last:
            b64 = last["image_base64"]
            blocks.append({
                "type": "input_image",
                "image_url": f"data:image/jpeg;base64,{b64}"
            })

        # PDF
        if "pdf_text" in last:
            pdf_text = clean_text(last["pdf_text"])
            blocks.append({"type": "input_text", "text": f"[PDF ë‚´ìš©]\n{pdf_text}"})

        # TXT (ê¸¸ë©´ ìë™ ë¶„í• )
        if "txt_text" in last:
            txt_text = clean_text(last["txt_text"])
            chunks = chunk_text(txt_text)
            if len(chunks) > 1:
                summary_results = []
                for idx, chunk in enumerate(chunks, 1):
                    print(f"ğŸ“„ TXT ì¡°ê° {idx}/{len(chunks)} ë¶„ì„ ì¤‘...")
                    response = client.responses.create(
                        model=model,
                        input=[{"role": "user", "content": [
                            {"type": "input_text", "text": f"[TXT {idx}/{len(chunks)}]\n{chunk}"}
                        ]}],
                        max_output_tokens=4000,
                    )
                    part_text = getattr(response, "output_text", None)
                    if not part_text and hasattr(response, "output"):
                        for out in response.output:
                            for c in getattr(out, "content", []):
                                if hasattr(c, "text"):
                                    part_text = c.text
                    summary_results.append(part_text or "")
                    time.sleep(1)  # API ê³¼ë¶€í•˜ ë°©ì§€

                # ì¡°ê° ìš”ì•½ë³¸ì„ í†µí•© ë¶„ì„
                final_prompt = (
                    "ë‹¤ìŒì€ ì—¬ëŸ¬ TXT ì¡°ê° ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.\n"
                    "ì´ ì „ì²´ ë‚´ìš©ì„ ì¢…í•©ì ìœ¼ë¡œ ìš”ì•½ ë° ë¶„ì„í•´ì£¼ì„¸ìš”.\n\n"
                    + "\n\n".join(summary_results)
                )
                blocks.append({"type": "input_text", "text": final_prompt})
            else:
                blocks.append({"type": "input_text", "text": f"[TXT íŒŒì¼ ë‚´ìš©]\n{txt_text}"})

        if not blocks:
            blocks.append({"type": "input_text", "text": "ë‚´ìš© ì—†ìŒ"})

        # ìµœì¢… GPT í˜¸ì¶œ
        response = client.responses.create(
            model=model,
            input=[{"role": "user", "content": blocks}],
            max_output_tokens=4000,
        )

        # ì‘ë‹µ íŒŒì‹±
        if hasattr(response, "output_text") and response.output_text:
            return response.output_text
        if hasattr(response, "output"):
            for out in response.output:
                for c in getattr(out, "content", []):
                    if hasattr(c, "text"):
                        return c.text

        return "âš ï¸ GPTë¡œë¶€í„° ì‘ë‹µì´ ì˜¤ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    except Exception as e:
        print("OpenAI API í˜¸ì¶œ ì—ëŸ¬:", e, flush=True)
        return f"âš ï¸ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
